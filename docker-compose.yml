# Docker Compose configuration for RAG application using host machine's Ollama
# This configuration connects to a locally installed Ollama for better performance

services:
  # Main application service: Streamlit UI and RAG pipeline
  webapp:
    build: .
    volumes:
      - ./app.py:/app/app.py  # app.py from host
      - ./startup.sh:/app/startup.sh  # Startup script
      - faiss_data:/app/data  # Use named volume for FAISS data (isolated in Docker)
      - doc_storage:/app/documents  # Use named volume for documents (isolated in Docker)
    ports:
      - "8501:8501"  # Expose Streamlit web interface
    restart: unless-stopped
    environment:
      - PYTHONUNBUFFERED=1
      # This connects to the host machine's Ollama installation
      - OLLAMA_HOST=host.docker.internal
    extra_hosts:
      - "host.docker.internal:host-gateway"  # For Linux compatibility
    # Using external script instead of inline commands
    entrypoint: ["/bin/bash", "/app/startup.sh"]

# Persistent volumes definition
volumes:
  faiss_data:   # Stores FAISS indices (isolated in Docker)
  doc_storage:  # Stores uploaded documents (isolated in Docker)